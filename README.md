# BSc-Project 2020
Third Year BSc Physics Project 2019/20 on Adversarial Attacks on a CNN Model

Abstract: Convolutional Neural Networks are being widely used in building particle classifier systems in high energy physics experiments. There are a number of factors in detectors that could alter the observed images of particle tracks. These detector factors are likely to be sources of adversarial examples in a CNN model which could lead to misclassifications. We built a particle classifier based on CNN using a set of simulated images provided. An accuracy of 0.96 Â± 0.05 was achieved. The f1-score for each class was close to 1, indicating a good performance of the model. We considered a number of detector effects: dead channel, hot pixels, neutron radiation, cracks in solid detectors, and space charge. The physics of these effects was discussed. The effects were implemented on the images as adversarial attacks as accurately and as physically as possible. Multiple aspects of each attack were investigated. The response of these adversarial examples on the model built was observed. We found that many of the attacks could indeed cause misclassifications of the particle class. The misclassifications depended heavily on the nature of the detector effects. 

WARNING: The codes and the project report are mine. They are only for educational purposes. Please refer to them at your own risk. Irresponsibly copying the work can result in severe plagiarism allegations by your institution. I am not responsible for such action.
